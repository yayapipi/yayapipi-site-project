<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>new on Yayapipi Studio</title>
    <link>https://yayapipi.github.io/categories/new/</link>
    <description>Recent content in new on Yayapipi Studio</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 15 Sep 2020 11:30:03 +0000</lastBuildDate><atom:link href="https://yayapipi.github.io/categories/new/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用PYTHON實作抓取博客來圖書資料</title>
      <link>https://yayapipi.github.io/posts/python-worm/</link>
      <pubDate>Tue, 15 Sep 2020 11:30:03 +0000</pubDate>
      
      <guid>https://yayapipi.github.io/posts/python-worm/</guid>
      <description>在這個網絡世界資訊爆棚的時代，我們常常需要抓取網站上面的各種資料進行處理，因為最近在寫一個可以記錄你讀過多少本書的網站，所以今天我們就要來試試看使用Python 的Beautiful Soup來抓取博客來上面的圖書資料！
準備工具:
 安裝好Python的環境 安裝BeautifulSoup4 pip install beautifulsoup4  我們可以看到頁面上提供了很多我們要提取的資訊，現在我們要透過CMD進行關鍵字的搜尋，然後抓取搜尋界面的資訊，我們要抓的資訊有書本的照片，標題，和對應跳轉網址，抓到網址之後，我們會進去網址裡面繼續抓更多的資訊
我們先來看看搜尋界面的代碼：
import requests import sys from bs4 import BeautifulSoupr = requests.get(‘https://search.books.com.tw/search/query/key/’+sys.argv[1]) if r.status_code == requests.codes.ok: # 以 BeautifulSoup 解析 HTML 程式碼 soup = BeautifulSoup(r.text, ‘html.parser’) #print(soup.prettify()) 這是把抓取的HTML美化列印出來 # 抓出搜尋到的所有資料 stories = soup.find_all(‘a’,rel=’mid_image’) for s in stories: #抓出書名 print(“標題：” + s.get(‘title’)) #抓出對應的網址 href_cut_start = ‘item/’ href_cut_end = ‘/page/’ href = s.get(‘href’) href = href[href.index(href_cut_start)+len(href_cut_start):href.index(href_cut_end)] print(“網址：” + href) image = soup.</description>
    </item>
    
  </channel>
</rss>
