<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Yayapipi Studio</title>
    <link>https://yayapipi.github.io/posts/</link>
    <description>Recent content in Posts on Yayapipi Studio</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 06 Dec 2020 00:02:58 +0800</lastBuildDate><atom:link href="https://yayapipi.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hugo一鍵發佈Bat</title>
      <link>https://yayapipi.github.io/posts/hugo%E4%B8%80%E9%8D%B5%E7%99%BC%E4%BD%88bat/</link>
      <pubDate>Sun, 06 Dec 2020 00:02:58 +0800</pubDate>
      
      <guid>https://yayapipi.github.io/posts/hugo%E4%B8%80%E9%8D%B5%E7%99%BC%E4%BD%88bat/</guid>
      <description>快速生成新文章：
@echo off set /p id=&amp;#34;Enter Article Name: &amp;#34; hugo new %id% echo %id% is created pause 一鍵部署發佈：
@echo off set /p commit=&amp;#34;Enter Commit Value: &amp;#34; hugo cd public git add . git commit -m &amp;#34;%commit%&amp;#34; git push -u origin master echo Commit Pushed pause </description>
    </item>
    
    <item>
      <title>New2</title>
      <link>https://yayapipi.github.io/posts/new2/</link>
      <pubDate>Sat, 05 Dec 2020 23:55:23 +0800</pubDate>
      
      <guid>https://yayapipi.github.io/posts/new2/</guid>
      <description>New Files</description>
    </item>
    
    <item>
      <title>Pixel To The West</title>
      <link>https://yayapipi.github.io/posts/pixel-to-the-west/</link>
      <pubDate>Tue, 15 Sep 2020 11:30:03 +0000</pubDate>
      
      <guid>https://yayapipi.github.io/posts/pixel-to-the-west/</guid>
      <description></description>
    </item>
    
    <item>
      <title>使用PYTHON實作抓取博客來圖書資料&#34;</title>
      <link>https://yayapipi.github.io/posts/python-worm/</link>
      <pubDate>Tue, 15 Sep 2020 11:30:03 +0000</pubDate>
      
      <guid>https://yayapipi.github.io/posts/python-worm/</guid>
      <description>在這個網絡世界資訊爆棚的時代，我們常常需要抓取網站上面的各種資料進行處理，因為最近在寫一個可以記錄你讀過多少本書的網站，所以今天我們就要來試試看使用Python 的Beautiful Soup來抓取博客來上面的圖書資料！
準備工具:
 安裝好Python的環境 安裝BeautifulSoup4 pip install beautifulsoup4  我們可以看到頁面上提供了很多我們要提取的資訊，現在我們要透過CMD進行關鍵字的搜尋，然後抓取搜尋界面的資訊，我們要抓的資訊有書本的照片，標題，和對應跳轉網址，抓到網址之後，我們會進去網址裡面繼續抓更多的資訊
我們先來看看搜尋界面的代碼：
import requests import sys from bs4 import BeautifulSoupr = requests.get(‘https://search.books.com.tw/search/query/key/’+sys.argv[1]) if r.status_code == requests.codes.ok: # 以 BeautifulSoup 解析 HTML 程式碼 soup = BeautifulSoup(r.text, ‘html.parser’) #print(soup.prettify()) 這是把抓取的HTML美化列印出來 # 抓出搜尋到的所有資料 stories = soup.find_all(‘a’,rel=’mid_image’) for s in stories: #抓出書名 print(“標題：” + s.get(‘title’)) #抓出對應的網址 href_cut_start = ‘item/’ href_cut_end = ‘/page/’ href = s.get(‘href’) href = href[href.index(href_cut_start)+len(href_cut_start):href.index(href_cut_end)] print(“網址：” + href) image = soup.</description>
    </item>
    
  </channel>
</rss>
